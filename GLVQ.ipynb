{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Created By  : Tushar Mehta\n",
    "# Created Date: 25/01/2023\n",
    "# version ='1.0'\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Datasets and class\n",
    "X_dataset = pd.read_csv('GLVQData/train_data.csv', header=None).values\n",
    "Y_dataset = pd.read_csv('GLVQData/train_target.csv', squeeze=True, header=None).values\n",
    "X_test = pd.read_csv('GLVQData/test_data.csv').values\n",
    "\n",
    "# Changing the names to numbers\n",
    "Y_dataset, Original = pd.factorize(Y_dataset)\n",
    "\n",
    "# Standardizing the data\n",
    "X_dataset -= X_dataset.mean(0)\n",
    "X_dataset = X_dataset / X_dataset.std(0)\n",
    "\n",
    "X_test -= X_test.mean(0)\n",
    "X_test = X_test / X_test.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(A, B):\n",
    "    difference = A[None, :] - B[:, None]\n",
    "    square = difference * difference\n",
    "    squared_sum = square.sum(axis=-1)\n",
    "    distance = np.sqrt(squared_sum)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "def GLVQ(X_dataset, Y_dataset, protos, protos_class, epoch, lt, lr):\n",
    "    for _ in range(epoch):\n",
    "        epoch_index = rng.choice(len(X_dataset))\n",
    "        datapoint = X_dataset[epoch_index] # random datapoint\n",
    "        datapoint_class = Y_dataset[epoch_index] # class of the datapoint\n",
    "        distances = pairwise_distance(protos, datapoint[None,:])[0] # distance between all protoypes and random chosen datapoint\n",
    "        # Initializing empty list and empty array\n",
    "        d_plus = []\n",
    "        d_plus_class = []\n",
    "        d_minus = []\n",
    "        d_minus_class = []\n",
    "        matching_protos = np.array([])\n",
    "        nonmatching_protos = np.array([])\n",
    "\n",
    "        for i in range(len(protos_class)):\n",
    "            # Datapoint and Prototypes with same class\n",
    "            if datapoint_class == protos_class[i]: \n",
    "                d_plus.append(distances[i])\n",
    "                d_plus_class.append(protos_class[i])\n",
    "                if matching_protos.size > 0:\n",
    "                    new_proto = np.expand_dims(protos[i], axis= 0)\n",
    "                else:\n",
    "                    new_proto = protos[i]\n",
    "                matching_protos = np.append(matching_protos, new_proto, axis= 0)\n",
    "                if matching_protos.size < 4:\n",
    "                    matching_protos = np.expand_dims(matching_protos, axis= 0)\n",
    "            # Datapoint and prototypes of different class\n",
    "            else:\n",
    "                d_minus.append(distances[i])\n",
    "                d_minus_class.append(protos_class[i])\n",
    "                if nonmatching_protos.size > 0:\n",
    "                    new_proto = np.expand_dims(protos[i], axis= 0)\n",
    "                else:\n",
    "                    new_proto = protos[i]\n",
    "                nonmatching_protos = np.append(nonmatching_protos, new_proto, axis= 0)\n",
    "                if nonmatching_protos.size < 4:\n",
    "                    nonmatching_protos = np.expand_dims(nonmatching_protos, axis= 0)\n",
    "\n",
    "        d_plus = np.array(d_plus)\n",
    "        d_plus_class = np.array(d_plus_class)\n",
    "        d_minus = np.array(d_minus)\n",
    "        d_minus_class = np.array(d_minus_class)\n",
    "        d_plus_winner = d_plus.argmin() # index of minimum distance of the datapoint with the matching prototype\n",
    "        w_plus = matching_protos[d_plus_winner] # closest matching prototype\n",
    "        d_minus_winner = d_minus.argmin() # index of minimum distance of the datapoint with the nonmatching prototype\n",
    "        w_minus = nonmatching_protos[d_minus_winner] # closest nonmatching prototype\n",
    "\n",
    "        classifier_function = (d_plus[d_plus_winner] - d_minus[d_minus_winner]) / (d_plus[d_plus_winner] + d_minus[d_minus_winner])\n",
    "        \n",
    "        f = 1/(1 + np.exp(-lt*classifier_function))\n",
    "        # Update rules\n",
    "        w_plus +=  lr * (f*(1 - f)) * (d_minus[d_minus_winner]/ np.square(d_plus[d_plus_winner] + d_minus[d_minus_winner])) * (datapoint - w_plus)\n",
    "        w_minus -= lr * (f*(1 - f)) * (d_plus[d_plus_winner]/ np.square(d_plus[d_plus_winner] + d_minus[d_minus_winner])) * (datapoint - w_minus)\n",
    "\n",
    "        matching_protos[d_plus_winner] = w_plus\n",
    "        nonmatching_protos[d_minus_winner] = w_minus\n",
    "        protos = np.append(matching_protos, nonmatching_protos, axis= 0)\n",
    "        protos_class = d_plus_class.tolist() + d_minus_class.tolist()\n",
    "\n",
    "    return protos, protos_class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using idea from GridSearhCV to get the best epoch, lt and lr (More the number of parameters more time it will take for one whole loop to run)\n",
    "for _ in range(10):\n",
    "    param_grid = {'epoch': [900, 1000, 1100, 1200],\n",
    "                'lt': [3, 4, 5],\n",
    "                'lr': [0.2, 0.3, 0.4, 0.5],\n",
    "                # 'lr' : [0.01, 0.03, 0.05, 0.07]\n",
    "                # 'ppc': [2,3,4]\n",
    "                }\n",
    "    best_params = {'epoch': None, 'lt':None, 'lr':None, 'ppc':None}\n",
    "    best_score = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_dataset):\n",
    "        X_train, X_test = X_dataset[train_index], X_dataset[test_index]\n",
    "        Y_train, Y_test = Y_dataset[train_index], Y_dataset[test_index]\n",
    "        for epoch in param_grid['epoch']:\n",
    "            for lt in param_grid['lt']:\n",
    "                for lr in param_grid['lr']:\n",
    "                    # for prototype_per_class in param_grid['ppc']:\n",
    "                    prototype_per_class = 2\n",
    "                    num_classes = len(np.unique(Y_dataset))\n",
    "                    rng = np.random.default_rng()\n",
    "                    protos = rng.random(size=(num_classes*prototype_per_class,X_train.shape[-1]))\n",
    "                    protos = np.asarray(protos)\n",
    "                    protos_class = list(np.unique(Y_dataset))*prototype_per_class\n",
    "\n",
    "                    protos, protos_class = GLVQ(X_dataset=X_dataset, Y_dataset=Y_dataset, protos= protos, protos_class= protos_class, epoch= epoch, lt= lt, lr= lr)    \n",
    "                    \n",
    "                    prediction = []\n",
    "                    for i in range(len(X_test)):\n",
    "                        distances = pairwise_distance(protos, X_test[i][None,:])[0]\n",
    "                        prediction.append(protos_class[np.argmin(distances)])\n",
    "                    score = accuracy_score(Y_test, prediction)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params['epoch'] = epoch\n",
    "                        best_params['lt'] = lt\n",
    "                        best_params['lr'] = lr\n",
    "                        best_params['ppc'] = prototype_per_class\n",
    "\n",
    "    print(\"Best Parameters: \", best_params)\n",
    "    print(\"Best Score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation using KFold to check the accuracy score.\n",
    "\n",
    "for _ in range(10):\n",
    "    kf = KFold(n_splits=6)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_dataset):\n",
    "        X_train, X_test = X_dataset[train_index], X_dataset[test_index]\n",
    "        Y_train, Y_test = Y_dataset[train_index], Y_dataset[test_index]\n",
    "        # Training Loop\n",
    "        epoch = 1000\n",
    "        lt = 4 # Learning Time\n",
    "        lr = 0.5 # Learning Rate\n",
    "        prototype_per_class = 2\n",
    "        num_classes = len(np.unique(Y_dataset))\n",
    "        rng = np.random.default_rng()\n",
    "        protos = rng.random(size=(num_classes*prototype_per_class,X_dataset.shape[-1]))\n",
    "        protos = np.asarray(protos)\n",
    "        protos_class = list(np.unique(Y_dataset))*prototype_per_class\n",
    "\n",
    "        protos, protos_class = GLVQ(X_dataset=X_dataset, Y_dataset=Y_dataset, protos= protos, protos_class= protos_class, epoch= epoch, lt= lt, lr= lr)\n",
    "\n",
    "            \n",
    "        prediction = []\n",
    "        for i in range(len(X_test)):\n",
    "            # print(protos, X_test[i])\n",
    "            distances = pairwise_distance(protos, X_test[i][None,:])[0]\n",
    "            prediction.append(protos_class[np.argmin(distances)])\n",
    "        score = accuracy_score(Y_test, prediction)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))\n",
    "    # print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Prototypes\n",
    "prototype_per_class = 2\n",
    "num_classes = len(np.unique(Y_dataset))\n",
    "rng = np.random.default_rng()\n",
    "protos = rng.random(size=(num_classes*prototype_per_class,X_dataset.shape[-1]))\n",
    "protos = np.asarray(protos)\n",
    "\n",
    "protos_class = list(np.unique(Y_dataset))*prototype_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the datapoints in 2D for better Visualizing\n",
    "\n",
    "X_datasetnew = X_dataset[:, (0,2)]\n",
    "protosnew = protos[:, (0,2)]\n",
    "plt.figure()\n",
    "plt.scatter(*X_datasetnew.T, c=Y_dataset)\n",
    "plt.scatter(*protosnew.T, c=protos_class, s=500, marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch =1100\n",
    "lt = 4 # learning time\n",
    "lr = 0.4 # learning rate\n",
    "\n",
    "protos, protos_class = GLVQ(X_dataset=X_dataset, Y_dataset=Y_dataset, protos= protos, protos_class= protos_class, epoch= epoch, lt= lt, lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the datapoints and the prototypes in 2D\n",
    "X_datasetnew1 = X_dataset[:, (0,2)]\n",
    "protosnew1 = protos[:, (0,2)]\n",
    "plt.figure()\n",
    "plt.scatter(*X_datasetnew1.T, c=Y_dataset)\n",
    "plt.scatter(*protosnew1.T, c=protos_class, s=500, marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Visualizing the Datapoints and prototypes \n",
    "z, x, y = X_dataset[:, 2], X_dataset[:, 0], X_dataset[:, 1]\n",
    "Z, X, Y = protos[:, 2], protos[:, 0], protos[:, 1]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection= '3d')\n",
    "ax.scatter(x,y,z, c=Y_dataset, alpha= 1)\n",
    "ax.scatter(X,Y,Z, c=protos_class, s=500, marker= '*')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting class for the test dataset\n",
    "predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    distances_p = pairwise_distance(X_test[i], protos)\n",
    "    predictions.append(protos_class[np.argmin(distances_p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the predicted class and the test dataset with the prototypes\n",
    "X_datasetnew1 = X_test[:, (0,2)]\n",
    "protosnew2 = protos[:, (0,2)]\n",
    "plt.figure()\n",
    "plt.scatter(*X_datasetnew1.T, c=predictions)\n",
    "plt.scatter(*protosnew1.T, c=protos_class, s=500, marker='*')\n",
    "plt.show()\n",
    "# pd.DataFrame(Original[predictions]).to_csv(\"PredictedLabels_2Prototypes.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D visualizing the predictions\n",
    "z, x, y = X_test[:, 2], X_test[:, 0], X_test[:, 1]\n",
    "Z, X, Y = protos[:, 2], protos[:, 0], protos[:, 1]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection= '3d')\n",
    "ax.scatter(x,y,z, c=predictions, alpha= 1)\n",
    "ax.scatter(X,Y,Z, c=protos_class, s=500, marker= '*')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.-1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a42b847524e4d3c9c34de32cfd216731c042192c4d66398ff9fa720a9162a9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
